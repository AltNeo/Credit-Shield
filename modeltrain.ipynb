{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'medium_data.csv'\n",
    "#df = load_and_explore_data(file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def load_and_explore_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data and perform initial exploration\n",
    "    \"\"\"\n",
    "    print(\"Loading and exploring data...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Identify target variable\n",
    "    print(\"\\nUnique values in potential target variables:\")\n",
    "    for col in df.columns:\n",
    "        if 'risk' in col.lower() or 'grade' in col.lower() or 'rating' in col.lower():\n",
    "            print(f\"{col}: {df[col].unique()}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and exploring data...\n",
      "Dataset shape: (10000, 73)\n",
      "\n",
      "Data types:\n",
      "id                    int64\n",
      "member_id             int64\n",
      "loan_amnt             int64\n",
      "funded_amnt           int64\n",
      "funded_amnt_inv     float64\n",
      "                     ...   \n",
      "total_rev_hi_lim    float64\n",
      "inq_fi              float64\n",
      "total_cu_tl         float64\n",
      "inq_last_12m        float64\n",
      "default_ind           int64\n",
      "Length: 73, dtype: object\n",
      "\n",
      "Missing values:\n",
      "id                      0\n",
      "member_id               0\n",
      "loan_amnt               0\n",
      "funded_amnt             0\n",
      "funded_amnt_inv         0\n",
      "                    ...  \n",
      "total_rev_hi_lim     2157\n",
      "inq_fi              10000\n",
      "total_cu_tl         10000\n",
      "inq_last_12m        10000\n",
      "default_ind             0\n",
      "Length: 73, dtype: int64\n",
      "\n",
      "Summary statistics:\n",
      "                 id     member_id     loan_amnt   funded_amnt  \\\n",
      "count  1.000000e+04  1.000000e+04  10000.000000  10000.000000   \n",
      "mean   4.529738e+06  5.407038e+06  13901.900000  13827.425000   \n",
      "std    2.987387e+06  3.576201e+06   8114.993296   8079.707531   \n",
      "min    6.542600e+04  9.895700e+04   1000.000000   1000.000000   \n",
      "25%    1.551364e+06  1.803137e+06   8000.000000   8000.000000   \n",
      "50%    4.375089e+06  5.397180e+06  12000.000000  12000.000000   \n",
      "75%    7.048246e+06  8.499942e+06  19381.250000  19200.000000   \n",
      "max    1.022466e+07  1.208681e+07  35000.000000  35000.000000   \n",
      "\n",
      "       funded_amnt_inv      int_rate   installment    annual_inc  \\\n",
      "count     10000.000000  10000.000000  10000.000000  1.000000e+04   \n",
      "mean      13699.837113     13.979447    424.538195  7.158261e+04   \n",
      "std        8115.299906      4.425374    242.369003  4.863595e+04   \n",
      "min           0.000000      5.420000     21.810000  6.000000e+03   \n",
      "25%        7750.000000     10.990000    252.207500  4.500000e+04   \n",
      "50%       12000.000000     13.680000    375.490000  6.100000e+04   \n",
      "75%       19000.000000     17.100000    556.465000  8.600000e+04   \n",
      "max       35000.000000     26.060000   1406.450000  1.500000e+06   \n",
      "\n",
      "                dti   delinq_2yrs  ...  il_util  open_rv_12m  open_rv_24m  \\\n",
      "count  10000.000000  10000.000000  ...      0.0          0.0          0.0   \n",
      "mean      16.448701      0.222700  ...      NaN          NaN          NaN   \n",
      "std        7.607839      0.666595  ...      NaN          NaN          NaN   \n",
      "min        0.000000      0.000000  ...      NaN          NaN          NaN   \n",
      "25%       10.730000      0.000000  ...      NaN          NaN          NaN   \n",
      "50%       16.205000      0.000000  ...      NaN          NaN          NaN   \n",
      "75%       21.952500      0.000000  ...      NaN          NaN          NaN   \n",
      "max       34.990000     12.000000  ...      NaN          NaN          NaN   \n",
      "\n",
      "       max_bal_bc  all_util  total_rev_hi_lim  inq_fi  total_cu_tl  \\\n",
      "count         0.0       0.0       7843.000000     0.0          0.0   \n",
      "mean          NaN       NaN      29426.139742     NaN          NaN   \n",
      "std           NaN       NaN      25295.051466     NaN          NaN   \n",
      "min           NaN       NaN          0.000000     NaN          NaN   \n",
      "25%           NaN       NaN      13800.000000     NaN          NaN   \n",
      "50%           NaN       NaN      23100.000000     NaN          NaN   \n",
      "75%           NaN       NaN      36800.000000     NaN          NaN   \n",
      "max           NaN       NaN     333270.000000     NaN          NaN   \n",
      "\n",
      "       inq_last_12m   default_ind  \n",
      "count           0.0  10000.000000  \n",
      "mean            NaN      0.125700  \n",
      "std             NaN      0.331528  \n",
      "min             NaN      0.000000  \n",
      "25%             NaN      0.000000  \n",
      "50%             NaN      0.000000  \n",
      "75%             NaN      0.000000  \n",
      "max             NaN      1.000000  \n",
      "\n",
      "[8 rows x 53 columns]\n",
      "\n",
      "Unique values in potential target variables:\n",
      "grade: ['A' 'B' 'C' 'D' 'G' 'E' 'F']\n",
      "sub_grade: ['A1' 'A4' 'B3' 'C1' 'C4' 'D5' 'G3' 'A5' 'B5' 'C2' 'G2' 'A3' 'B2' 'B4'\n",
      " 'D1' 'E4' 'D3' 'A2' 'B1' 'G1' 'C5' 'C3' 'E3' 'D4' 'D2' 'G4' 'E5' 'E2'\n",
      " 'E1' 'F1' 'F4' 'G5' 'F2' 'F3' 'F5']\n"
     ]
    }
   ],
   "source": [
    "df= load_and_explore_data(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.copy()\n",
    "X = data.drop(columns=[\"grade\"])\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term 0     36 months\n",
      "Name: term, dtype: object\n",
      "sub_grade 0    B3\n",
      "Name: sub_grade, dtype: object\n",
      "emp_title 0    Teacher\n",
      "Name: emp_title, dtype: object\n",
      "emp_length 0    10+ years\n",
      "Name: emp_length, dtype: object\n",
      "home_ownership 0    MORTGAGE\n",
      "Name: home_ownership, dtype: object\n",
      "verification_status 0    Verified\n",
      "Name: verification_status, dtype: object\n",
      "issue_d 0    01-12-2013\n",
      "Name: issue_d, dtype: object\n",
      "pymnt_plan 0    n\n",
      "Name: pymnt_plan, dtype: object\n",
      "desc 0     \n",
      "Name: desc, dtype: object\n",
      "purpose 0    debt_consolidation\n",
      "Name: purpose, dtype: object\n",
      "title 0    Debt consolidation\n",
      "Name: title, dtype: object\n",
      "zip_code 0    112xx\n",
      "Name: zip_code, dtype: object\n",
      "addr_state 0    CA\n",
      "Name: addr_state, dtype: object\n",
      "earliest_cr_line 0    01-10-2000\n",
      "Name: earliest_cr_line, dtype: object\n",
      "initial_list_status 0    f\n",
      "Name: initial_list_status, dtype: object\n",
      "last_pymnt_d 0    01-01-2016\n",
      "Name: last_pymnt_d, dtype: object\n",
      "next_pymnt_d 0    01-02-2016\n",
      "Name: next_pymnt_d, dtype: object\n",
      "last_credit_pull_d 0    01-01-2016\n",
      "Name: last_credit_pull_d, dtype: object\n",
      "application_type 0    INDIVIDUAL\n",
      "Name: application_type, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_cols:\n",
    "    print(col, X[col].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_data(df, target_column):\n",
    "    \"\"\"\n",
    "    Preprocess data by handling missing values, encoding categorical features,\n",
    "    and splitting into training and testing sets\n",
    "    \"\"\"\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Handle missing values\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Fill missing numerical values with median\n",
    "    for col in numerical_cols:\n",
    "        if X[col].isnull().any():\n",
    "            X[col] = X[col].fillna(X[col].median())\n",
    "    \n",
    "    # Fill missing categorical values with mode\n",
    "    for col in categorical_cols:\n",
    "        if X[col].isnull().any():\n",
    "            X[col] = X[col].fillna(X[col].mode()[0])\n",
    "    \n",
    "    # Encode categorical features\n",
    "    encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        encoders[col] = le\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Testing set shape: {X_test.shape}\")\n",
    "    \n",
    "    preprocessing_artifacts = {\n",
    "        'encoders': encoders,\n",
    "        'scaler': scaler,\n",
    "        'feature_names': X.columns.tolist(),\n",
    "        'categorical_cols': categorical_cols.tolist(),\n",
    "        'numerical_cols': numerical_cols.tolist(),\n",
    "    }\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, preprocessing_artifacts\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train Random Forest model\n",
    "    \"\"\"\n",
    "    print(\"\\nTraining model...\")\n",
    "    \n",
    "    # Random Forest\n",
    "    print(\"Training Random Forest model...\")\n",
    "    rf_model = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    \n",
    "    # Parameter grid for training with larger dataset\n",
    "    rf_param_grid = {\n",
    "        'n_estimators': [200, 300],\n",
    "        'max_depth': [None, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    \n",
    "    rf_grid = GridSearchCV(\n",
    "        rf_model, rf_param_grid, cv=5, scoring='f1_weighted', n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"Starting grid search at {datetime.now().strftime('%H:%M:%S')}...\")\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    print(f\"Completed grid search at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    print(f\"Best Random Forest parameters: {rf_grid.best_params_}\")\n",
    "    best_model = rf_grid.best_estimator_\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"RandomForest\"):\n",
    "    \"\"\"\n",
    "    Evaluate model performance\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.savefig(f'models/confusion_matrix_{model_name}.png')\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Try calculating ROC AUC (works for binary classification)\n",
    "    try:\n",
    "        if len(set(y_test)) == 2:\n",
    "            roc_auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "            print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "            \n",
    "            # ROC Curve\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'ROC Curve - {model_name}')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'models/roc_curve_{model_name}.png')\n",
    "    except:\n",
    "        print(\"ROC AUC calculation skipped (not applicable for multiclass)\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'report': report,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob\n",
    "    }\n",
    "\n",
    "def export_model(model_results, artifacts, target_column, model_name=\"RandomForest\"):\n",
    "    \"\"\"\n",
    "    Export the model\n",
    "    \"\"\"\n",
    "    print(\"\\nExporting model...\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # Remove any existing models\n",
    "    for file in os.listdir('models'):\n",
    "        file_path = os.path.join('models', file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "                print(f\"Removed old model file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing {file_path}: {e}\")\n",
    "    \n",
    "    # Save model\n",
    "    model = model_results['model']\n",
    "    \n",
    "    # Ensure model has predict and predict_proba methods before saving\n",
    "    if not hasattr(model, 'predict'):\n",
    "        raise ValueError(f\"Model does not have predict method: {type(model)}\")\n",
    "    if not hasattr(model, 'predict_proba'):\n",
    "        print(f\"WARNING: Model does not have predict_proba method: {type(model)}\")\n",
    "    \n",
    "    # Save RandomForest model using pickle for consistency with app.py's load mechanism\n",
    "    model_path = f'models/randomforest_model.pkl'\n",
    "    with open(model_path, 'wb') as f:\n",
    "        import pickle  # Use pickle here for consistency\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    # Create a copy as best_model for compatibility\n",
    "    best_model_path = f'models/best_model.pkl'\n",
    "    with open(best_model_path, 'wb') as f:\n",
    "        import pickle\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {best_model_path}\")\n",
    "    \n",
    "    # Save preprocessing artifacts using pickle for consistency\n",
    "    artifacts_path = 'models/preprocessing_artifacts.pkl'\n",
    "    artifacts['target_column'] = target_column\n",
    "    with open(artifacts_path, 'wb') as f:\n",
    "        import pickle\n",
    "        pickle.dump(artifacts, f)\n",
    "    print(f\"Preprocessing artifacts saved to {artifacts_path}\")\n",
    "    \n",
    "    # Test load to verify the model can be loaded\n",
    "    print(\"Verifying model load works...\")\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            import pickle\n",
    "            test_model = pickle.load(f)\n",
    "        # Verify it has required methods\n",
    "        if hasattr(test_model, 'predict'):\n",
    "            print(\"✅ Verified model can be loaded and has predict method\")\n",
    "        else:\n",
    "            print(\"❌ Loaded model does not have predict method!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error verifying model load: {e}\")\n",
    "    \n",
    "    # Create model metrics JSON file\n",
    "    metrics = {\n",
    "        'models': {\n",
    "            'RandomForest': {\n",
    "                'accuracy': float(model_results['accuracy']),\n",
    "                'precision': float(model_results['precision']),\n",
    "                'recall': float(model_results['recall']),\n",
    "                'f1': float(model_results['f1'])\n",
    "            }\n",
    "        },\n",
    "        'best_model': model_name,\n",
    "        'input_features': artifacts['feature_names'],\n",
    "        'target_column': target_column,\n",
    "        'categorical_features': artifacts['categorical_cols'],\n",
    "        'numerical_features': artifacts['numerical_cols'],\n",
    "        'dataset_size': 10000,\n",
    "        'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    metrics_path = 'models/model_metrics.json'\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    print(f\"Model metrics saved to {metrics_path}\")\n",
    "    \n",
    "    # Create a feature importance plot\n",
    "    try:\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_names = artifacts['feature_names']\n",
    "            importances = model.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            \n",
    "            # Show only top 30 features for readability\n",
    "            top_n = min(30, len(indices))\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.title(f'Top {top_n} Feature Importances - {model_name}')\n",
    "            plt.bar(range(top_n), importances[indices[:top_n]], align='center')\n",
    "            plt.xticks(range(top_n), [feature_names[i] for i in indices[:top_n]], rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'models/feature_importance.png')\n",
    "            print(f\"Feature importance plot saved to models/feature_importance.png\")\n",
    "            \n",
    "            # Also save feature importances as CSV\n",
    "            importance_df = pd.DataFrame({\n",
    "                'Feature': [feature_names[i] for i in indices],\n",
    "                'Importance': importances[indices]\n",
    "            })\n",
    "            importance_df.to_csv('models/feature_importance.csv', index=False)\n",
    "            print(f\"Feature importance data saved to models/feature_importance.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate feature importance plot: {str(e)}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the credit risk model development\n",
    "    \"\"\"\n",
    "    # Load and explore data\n",
    "    file_path = 'medium_data.csv'\n",
    "    df = load_and_explore_data(file_path)\n",
    "    \n",
    "    # Identify target column - adjust based on actual data exploration\n",
    "    target_columns = [col for col in df.columns if 'risk' in col.lower() or \n",
    "                     'grade' in col.lower() or 'rating' in col.lower()]\n",
    "    \n",
    "    if not target_columns:\n",
    "        print(\"Could not automatically identify target column. Using 'grade'\")\n",
    "        target_column = 'grade'  # Default target column\n",
    "    else:\n",
    "        target_column = target_columns[0]\n",
    "        print(f\"Identified target column: {target_column}\")\n",
    "    \n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test, preprocessing_artifacts = preprocess_data(df, target_column)\n",
    "    \n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    model_results = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # Export model\n",
    "    export_model(model_results, preprocessing_artifacts, target_column)\n",
    "    \n",
    "    print(\"\\nCredit risk model development completed successfully!\")\n",
    "    print(f\"Random Forest model F1 score: {model_results['f1']:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
